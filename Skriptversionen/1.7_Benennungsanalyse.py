import tkinter as tk
from tkinter import filedialog

import pandas as pd
import re
import json
import os
import xml.etree.ElementTree as ET
import copy

from typing import Optional, Dict, Union
from xml.etree.ElementTree import Element
from openpyxl import load_workbook


DatenTyp = Dict[str, Optional[Union[pd.DataFrame, Element]]]
tei_ns = {'tei': 'http://www.tei-c.org/ns/1.0'}

def initialisiere_projekt():
    """
    Fragt den Benutzer nach dem Buchnamen, legt projektbezogene JSON-Pfade an
    und lÃ¤dt ggf. vorhandene Fortschrittsdaten und fehlende Benennungen.
    Gibt ein Tupel zurÃ¼ck: (buchname, fehlende_benennungen, letzter_bearbeiteter_vers, pfade_dict)
    """

    buchname = input("Welches Buch bearbeiten wir heute? (z.â€¯B. Eneasroman): ").strip()

    # Verzeichnis anlegen
    os.makedirs("data", exist_ok=True)

    # Pfade vorbereiten (buchspezifisch)
    benennungen_json_path = os.path.join("data", f"fehlende_benennungen_{buchname}.json")
    progress_json_path = os.path.join("data", f"progress_{buchname}.json")
    kollokationen_json_path = os.path.join("data", f"kollokationen_{buchname}.json")
    kategorisierung_json_path = os.path.join("data", f"kategorisierung_{buchname}.json")
    lemma_normalisierung_json_path = os.path.join("data", f"lemma_normalisierung_{buchname}.json")
    ignorierte_lemmas_json_path = os.path.join("data", f"ignorierte_lemmas_{buchname}.json")
    lemma_kategorien_json_path = os.path.join("data", f"lemma_kategorien_{buchname}.json")

    paths = {
        "benennungen_json": benennungen_json_path,
        "progress_json": progress_json_path,
        "kollokationen_json": kollokationen_json_path,
        "kategorisierung_json": kategorisierung_json_path,
        "lemma_normalisierung_json": lemma_normalisierung_json_path,
        "ignorierte_lemmas_json": ignorierte_lemmas_json_path,
        "lemma_kategorien_json": lemma_kategorien_json_path
    }

    # Fortschritt laden oder auf 0 setzen
    letzter_bearbeiteter_vers = 0
    if os.path.exists(progress_json_path):
        with open(progress_json_path, "r", encoding="utf-8") as f:
            letzter_bearbeiteter_vers = json.load(f).get("letzter_vers", 0)

    # JSON-Dateien anlegen, falls sie fehlen
    initialisiere_dateien(paths)

    return buchname, letzter_bearbeiteter_vers, paths

def initialisiere_dateien(paths):
    """Legt die projektbezogenen JSON-Dateien an, falls sie noch nicht existieren."""

    def lege_an(pfad, inhalt):
        if not os.path.exists(pfad):
            with open(pfad, "w", encoding="utf-8") as f:
                json.dump(inhalt, f, indent=4, ensure_ascii=False)

    lege_an(paths["progress_json"], {"letzter_vers": 0})
    lege_an(paths["benennungen_json"], [])
    lege_an(paths["kollokationen_json"], [])
    lege_an(paths["kategorisierung_json"], [])

def lade_daten() -> DatenTyp:
    """Fragt interaktiv nach Excel- und TEI-Dateien, lÃ¤dt sie bei Zustimmung und gibt sie gesammelt zurÃ¼ck."""
    root = tk.Tk()
    root.withdraw()
    root.attributes("-topmost", True)

    daten: DatenTyp = {"excel": None, "xml": None}

    # 1. Excel-Tabelle laden oder neu anlegen
    antwort_excel = input("MÃ¶chtest du eine Excel-Tabelle mit bereits erhobenen Benennungen laden? (j/n): ").strip().lower()
    if antwort_excel == "j":
        excel_pfad = filedialog.askopenfilename(
            title="WÃ¤hle die Excel-Datei mit den Benennungen",
            initialdir=os.getcwd(),
            filetypes=[("Excel-Dateien", "*.xlsx")]
        )
        if excel_pfad:
            while True:
                try:
                    daten["excel"] = pd.read_excel(excel_pfad)
                    daten["excel"] = pruefe_pflichtspalten(daten["excel"])
                    print(f"âœ… Excel-Datei geladen: {os.path.basename(excel_pfad)}")
                    break  # erfolgreich geladen, Schleife beenden
                except PermissionError:
                    print("âŒ Die Excel-Datei ist aktuell geÃ¶ffnet oder gesperrt.")
                    print("ğŸ” Bitte schlieÃŸe die Datei und wÃ¤hle sie anschlieÃŸend erneut aus.")
                    excel_pfad = filedialog.askopenfilename(
                        title="WÃ¤hle die Excel-Datei mit den Benennungen erneut",
                        initialdir=os.getcwd(),
                        filetypes=[("Excel-Dateien", "*.xlsx")]
                    )
                    if not excel_pfad:
                        print("âš ï¸ Keine Datei ausgewÃ¤hlt â€“ Abbruch.")
                        break
                except Exception as e:
                    print(f"âŒ Fehler beim Laden der Excel-Datei: {e}")
                    break
        else:
            print("âš ï¸ Keine Excel-Datei ausgewÃ¤hlt.")

    elif antwort_excel == "n":
        neue_excel = input("MÃ¶chtest du stattdessen eine neue Excel-Datei anlegen? (j/n): ").strip().lower()
        if neue_excel == "j":
            speicherpfad = filedialog.asksaveasfilename(
                title="Speicherort fÃ¼r neue Excel-Datei wÃ¤hlen",
                defaultextension=".xlsx",
                initialdir=os.getcwd(),
                filetypes=[("Excel-Dateien", "*.xlsx")]
            )
            if speicherpfad:
                try:
                    vorlage_pfad = os.path.join(os.getcwd(), "vorlage_excel.xlsx")
                    wb = load_workbook(vorlage_pfad)
                    wb.save(speicherpfad)
                    daten["excel"] = pd.read_excel(speicherpfad)
                    daten["excel"] = pruefe_pflichtspalten(daten["excel"])
                    print(f"âœ… Neue Excel-Datei angelegt: {os.path.basename(speicherpfad)}")
                except Exception as e:
                    print(f"âŒ Fehler beim Erstellen der neuen Datei: {e}")
            else:
                print("âš ï¸ Kein Speicherort ausgewÃ¤hlt.")

    # 2. TEI-XML-Datei laden?
    antwort_xml = input("MÃ¶chtest du die dazugehÃ¶rige TEI-Datei laden? (j/n): ").strip().lower()
    if antwort_xml == "j":
        xml_pfad = filedialog.askopenfilename(
            title="WÃ¤hle die TEI-XML-Datei",
            initialdir=os.getcwd(),
            filetypes=[("XML-Dateien", "*.xml")]
        )
        if xml_pfad:
            try:
                tree = ET.parse(xml_pfad)
                root = tree.getroot()
                root = normalisiere_tei_text(root)
                daten["xml"] = root
                print(f"âœ… XML-Datei geladen: {os.path.basename(xml_pfad)}")
            except Exception as e:
                print(f"âŒ Fehler beim Laden der XML-Datei: {e}")
        else:
            print("âš ï¸ Keine XML-Datei ausgewÃ¤hlt.")

    return daten

def sortierte_eintraege(liste: list) -> list:
    """
    Gibt eine sortierte Kopie der EintrÃ¤ge zurÃ¼ck â€“ nach Vers und Benennungswert.
    Damit kÃ¶nnen zwei Listen stabil miteinander verglichen werden.
    """
    return sorted(
        copy.deepcopy(liste),
        key=lambda x: (
            x.get("Vers", 0),
            x.get("Eigennennung") or x.get("Bezeichnung") or x.get("ErzÃ¤hler") or ""
        )
    )

def pruefe_pflichtspalten(df: pd.DataFrame) -> pd.DataFrame:
    """
    PrÃ¼ft, ob alle Pflichtspalten im DataFrame vorhanden sind.
    Bei fehlenden Spalten wird nachgefragt, ob sie automatisch ergÃ¤nzt werden sollen.
    Gibt den ggf. erweiterten DataFrame zurÃ¼ck.
    """
    pflichtspalten = [
        "benannte figur",
        "vers",
        "eigennennung",
        "nennende figur",
        "bezeichnung",
        "erzÃ¤hler",
        "kollokationen"
    ]

    aktuelle_spalten_lower = [sp.lower() for sp in df.columns]
    fehlende_spalten = [sp for sp in pflichtspalten if sp not in aktuelle_spalten_lower]

    if not fehlende_spalten:
        print("âœ… Alle Pflichtspalten sind vorhanden.")
        return df

    print("âš ï¸ Folgende Pflichtspalten fehlen:")
    for spalte in fehlende_spalten:
        print(f"   â€“ {spalte}")

    for spalte in fehlende_spalten:
        antwort = input(f"MÃ¶chtest du die Spalte â€{spalte}â€œ automatisch ergÃ¤nzen? (j/n): ").strip().lower()
        if antwort == "j":
            df[spalte] = ""
            print(f"â• Spalte â€{spalte}â€œ ergÃ¤nzt (leer).")
        else:
            print(f"âš ï¸ Spalte â€{spalte}â€œ bleibt fehlend.")

    return df

def normalisiere_text(text):
    """Normalisiert einen gegebenen Text nach festgelegten Regeln."""
    ersetzungen = {
        'Ã¦': 'ae', 'Å“': 'oe',
        'Ã©': 'e', 'Ã¨': 'e', 'Ã«': 'e', 'Ã¡': 'a', 'Ã ': 'a',
        'Ã»': 'u', 'Ã®': 'i', 'Ã¢': 'a', 'Ã´': 'o', 'Ãª': 'e',
        'Ã¼': 'u', 'Ã¶': 'o', 'Ã¤': 'a',
        'ÃŸ': 'ss',
        'iu': 'ie', 'Ã¼e': 'ue'
    }

    if not text:
        return ""

    text = text.lower()
    for alt, neu in ersetzungen.items():
        text = text.replace(alt, neu)

    text = re.sub(r'\bv\b', 'f', text)  # Ersetze 'v' am Wortanfang durch 'f'
    text = re.sub(r'\s+', ' ', text)   # Mehrfache Leerzeichen zusammenfassen

    return text

def normalisiere_tei_text(root):
    """Normalisiert alle Texte innerhalb der TEI-Datei."""
    if root is None:
        return None

    normalisierte_verse = []
    for seg in root.findall('.//tei:seg', tei_ns):
        if seg.text:
            normalisierter_text = normalisiere_text(seg.text)
            seg.text = normalisierter_text
            normalisierte_verse.append(normalisierter_text)

    print("âœ… TEI-Text wurde normalisiert.")

    return root

def speichere_fortschritt(
    fehlende_benennungen,
    letzter_bearbeiteter_vers,
    paths,
    vorheriger_vers=None,
    vorherige_benennungen=None,
    kollokationen_daten=None,
    vorherige_kollokationen=None,
    kategorisierte_eintraege = None,
    vorherige_kategorisierte_eintraege = None
):
    """
    Speichert Fortschritt, Benennungen und ggf. Kollokationen nur,
    wenn sich im Vergleich zum vorherigen Stand etwas geÃ¤ndert hat.
    """

    # ğŸ“Œ Fortschritt speichern â€“ nur wenn sich etwas geÃ¤ndert hat
    if vorheriger_vers is None or letzter_bearbeiteter_vers != vorheriger_vers:
        with open(paths["progress_json"], "w", encoding="utf-8") as f:
            json.dump({"letzter_vers": letzter_bearbeiteter_vers}, f, indent=4, ensure_ascii=False)

    # ğŸ“Œ Benennungen speichern â€“ nur wenn sich etwas geÃ¤ndert hat
    if vorherige_benennungen is None or sortierte_eintraege(fehlende_benennungen) != sortierte_eintraege(vorherige_benennungen):
        with open(paths["benennungen_json"], "w", encoding="utf-8") as f:
            json.dump(fehlende_benennungen, f, indent=4, ensure_ascii=False)

    # ğŸ“Œ Kollokationen speichern â€“ nur wenn Ã¼bergeben und geÃ¤ndert
    if kollokationen_daten is not None:
        if vorherige_kollokationen is None or kollokationen_daten != vorherige_kollokationen:
            with open(paths["kollokationen_json"], "w", encoding="utf-8") as f:
                json.dump(kollokationen_daten, f, indent=4, ensure_ascii=False)

    # ğŸ“Œ Kategorisierung speichern â€“ nur wenn Ã¼bergeben und geÃ¤ndert
    if kategorisierte_eintraege is not None:
        if vorherige_kategorisierte_eintraege is None or sortierte_eintraege(kategorisierte_eintraege) != sortierte_eintraege(vorherige_kategorisierte_eintraege):
            with open(paths["kategorisierung_json"], "w", encoding="utf-8") as f:
                json.dump(kategorisierte_eintraege, f, indent=4, ensure_ascii=False)


def lade_oder_erweitere_benennungen_dict():
    """
    LÃ¤dt oder erstellt ein zentrales Dictionary mit Figurenbenennungen aus Excel-Dateien.
    RÃ¼ckgabe: dict mit Struktur {'Enthaltene BÃ¼cher': [...], 'Benennungen': {buch: [benennungen, ...]}}
    """

    os.makedirs("data", exist_ok=True)
    dict_path = os.path.join("data", "benennungen_dict.json")

    # Bestehendes Dict laden oder neues anlegen
    if os.path.exists(dict_path):
        with open(dict_path, "r", encoding="utf-8") as f:
            benennungen_dict = json.load(f)
        print(f"ğŸ“š Es wurde ein Dictionary gefunden.")
        buecher_liste = benennungen_dict.get("Enthaltene BÃ¼cher", [])
        if buecher_liste:
            print(f"ğŸ‘‰ Enthaltene BÃ¼cher: {', '.join(buecher_liste)}")
        else:
            print("ğŸ‘‰ Enthaltene BÃ¼cher: [leer]")
        erweitern = input("MÃ¶chtest du eine Datei ergÃ¤nzen? (j/n): ").strip().lower()
    else:
        benennungen_dict = {"Enthaltene BÃ¼cher": [], "Benennungen": {}}
        print("â— Es wurde noch kein Benennungs-Dictionary gefunden.")
        erweitern = "j"

    while erweitern == "j":
        print("ğŸ“‚ Bitte wÃ¤hle eine Excel-Datei mit Benennungsdaten aus.")
        tk.Tk().withdraw()
        file_path = filedialog.askopenfilename(title="Excel-Datei auswÃ¤hlen", filetypes=[("Excel-Dateien", "*.xlsx")])
        if not file_path:
            print("âš ï¸ Keine Datei gewÃ¤hlt. Vorgang abgebrochen.")
            break

        buchname = input("Wie lautet der Name des Buchs (z.â€¯B. Eneasroman)? ").strip()

        try:
            df = pd.read_excel(file_path)
            relevante_spalten = ["Eigennennung", "Bezeichnung", "ErzÃ¤hler"]
            benennungen = []

            for spalte in relevante_spalten:
                if spalte in df.columns:
                    benennungen.extend(df[spalte].dropna().tolist())

            # Doppelte entfernen und bereinigen
            benennungen = list(set(str(f).strip().lower() for f in benennungen if str(f).strip()))

        except Exception as e:
            print(f"âŒ Fehler beim Einlesen der Datei: {e}")
            break

        benennungen_dict["Enthaltene BÃ¼cher"].append(buchname)
        benennungen_dict["Benennungen"][buchname] = benennungen
        print(f"âœ… Buch '{buchname}' mit {len(benennungen)} Benennungen hinzugefÃ¼gt.")

        erweitern = input("MÃ¶chtest du eine Datei ergÃ¤nzen? (j/n): ").strip().lower()

    with open(dict_path, "w", encoding="utf-8") as f:
        json.dump(benennungen_dict, f, indent=4, ensure_ascii=False)
        print(f"ğŸ’¾ Aktuelles Dictionary unter: {dict_path}")

    return benennungen_dict

def durchsuche_tei_mit_dict(
    df,
    root,
    benennungen_dict,
    letzter_vers,
    paths,
    fehlende_benennungen,
    kollokationen_daten,
    pruefe_benennungen=True,
    fuehre_kollokationen_durch=False,
    fuehre_kategorisierung_durch=False,
    lemma_normalisierung=None,
    ignorierte_lemmas=None,
    lemma_kategorien=None,
    kategorisierte_eintraege=None):

    """
    DurchlÃ¤uft den TEI-Text ab gespeichertem Vers und fÃ¼hrt die gewÃ¤hlten PrÃ¼fungen aus.
    """

    if root is None or df is None or benennungen_dict is None:
        print("âš ï¸ UngÃ¼ltige Eingaben â€“ Abbruch.")
        return fehlende_benennungen

    verse = root.findall('.//tei:l', tei_ns)
    if not verse:
        print("âš ï¸ Keine Verse gefunden.")
        return fehlende_benennungen

    start_index = next((i for i, line in enumerate(verse) if int(line.get("n")) >= letzter_vers), 0)

    print(f"ğŸ” Starte Durchlauf ab Vers {int(verse[start_index].get('n'))} (Index {start_index})")

    for line in verse[start_index:]:
        vers_nr = int(line.get("n"))

        verse_text = ' '.join([seg.text for seg in line.findall(".//tei:seg", tei_ns) if seg.text])
        normalized_verse = normalisiere_text(verse_text)

        if pruefe_benennungen:
            fehlende_benennungen = pruefe_und_ergaenze_benennungen(
                vers_nr, verse_text, normalized_verse, df, benennungen_dict, fehlende_benennungen, root, paths
            )

        if fuehre_kollokationen_durch:
            pruefe_und_ergaenze_kollokationen(
                vers_nr, df, kollokationen_daten, root, paths
            )

        if fuehre_kategorisierung_durch:
            eintraege = df[df["Vers"] == vers_nr].to_dict(orient="records")
            for entry in eintraege:
                annotiert = lemmatisiere_und_kategorisiere_eintrag(
                    entry,
                    lemma_normalisierung,
                    ignorierte_lemmas,
                    lemma_kategorien
                )
                if annotiert:
                    kategorisierte_eintraege.append(annotiert)

        # Fortschritt speichern
        speichere_fortschritt(
            fehlende_benennungen=fehlende_benennungen,
            letzter_bearbeiteter_vers=vers_nr,
            paths=paths
        )

    return fehlende_benennungen


def pruefe_und_ergaenze_benennungen(
    vers_nr: int,
    verse_text: str,
    normalized_verse: str,
    df: pd.DataFrame,
    benennungen_dict: dict,
    fehlende_benennungen: list,
    root: Element,
    paths: dict
) -> list:
    """
    PrÃ¼ft, ob eine Benennung aus dem globalen Dict im aktuellen Vers vorkommt,
    aber nicht in Excel oder in bereits bestÃ¤tigten/abgelehnten Benennungen.
    Bei Treffer: Interaktive ErgÃ¤nzung + Speicherung.
    """

    # 1. Benennungen aus Excel fÃ¼r diesen Vers extrahieren
    vorhandene_benennungen = set()
    if "Vers" in df.columns:
        df_vers = df[df["Vers"] == vers_nr]
        for spalte in ["Eigennennung", "Bezeichnung", "ErzÃ¤hler"]:
            if spalte in df_vers.columns:
                werte = df_vers[spalte].dropna().tolist()
                vorhandene_benennungen.update(
                    normalisiere_text(str(wert).strip()) for wert in werte if str(wert).strip()
                )

    # 2. Benennungen aus Dict extrahieren & normalisieren
    dict_benennungen = set()
    for buchliste in benennungen_dict.get("Benennungen", {}).values():
        dict_benennungen.update(
            normalisiere_text(name.strip()) for name in buchliste if name.strip()
        )

    # 3. FundprÃ¼fung & Benutzerinteraktion
    for benennung in dict_benennungen:
        if not benennung:
            continue

        # Ã¼berspringen, wenn bereits in Excel oder JSON behandelt
        if any(benennung in eintrag for eintrag in vorhandene_benennungen) or any(
            vers_nr == eintrag.get("Vers") and
            normalisiere_text(benennung) == normalisiere_text(
                eintrag.get("Eigennennung") or eintrag.get("Bezeichnung") or eintrag.get("ErzÃ¤hler") or ""
            )
            for eintrag in fehlende_benennungen
        ):
            continue

        if not re.search(rf'\b{re.escape(benennung)}\b', normalized_verse):
            continue

        print("\n" + "-" * 60)
        print(f"â— Neue Benennung gefunden, die nicht in der Excel-Datei existiert!")
        print(f"ğŸ” Gefundene Benennung: \"{benennung}\"")

        # ğŸ“– Kontext anzeigen
        prev_line = root.find(f'.//tei:l[@n="{vers_nr - 1}"]', tei_ns)
        if prev_line is not None:
            prev_text = ' '.join([seg.text for seg in prev_line.findall('.//tei:seg', tei_ns) if seg.text])
            print(f"ğŸ“– Vorheriger Vers ({vers_nr - 1}): {prev_text}")

        highlighted = verse_text.replace(benennung, f"\033[1m\033[93m{benennung}\033[0m")
        print(f"ğŸ“– Vers ({vers_nr}): {highlighted}")

        next_line = root.find(f'.//tei:l[@n="{vers_nr + 1}"]', tei_ns)
        if next_line is not None:
            next_text = ' '.join([seg.text for seg in next_line.findall('.//tei:seg', tei_ns) if seg.text])
            print(f"ğŸ“– NÃ¤chster Vers ({vers_nr + 1}): {next_text}")

        # ğŸ§ Benutzerabfrage
        confirm = input("Ist dies eine fehlende Benennung? (j/n): ").strip().lower()
        if confirm == "n":
            fehlende_benennungen.append({
                "Vers": vers_nr,
                "Eigennennung": benennung,
                "Nennende Figur": "",
                "Bezeichnung": "",
                "ErzÃ¤hler": "",
                "Status": "abgelehnt"
            })
            speichere_fortschritt(fehlende_benennungen, vers_nr, paths)
            print("âœ… Ablehnung gespeichert.")
            continue

        erweitern = input("ğŸ’¡ MÃ¶glicherweise ist dies eine mehrteilige Benennung. Erweitern? (j/n): ").strip().lower()
        if erweitern == "j":
            benennung = input("âœ Gib die vollstÃ¤ndige Benennung ein: ").strip()

        print("Bitte wÃ¤hle die richtige Kategorie:")
        print("[1] Eigennennung")
        print("[2] Bezeichnung")
        print("[3] ErzÃ¤hler")
        print("[4] Ãœberspringen")

        choice = input("ğŸ‘‰ Deine Auswahl: ").strip()
        if choice == "4":
            continue

        benannte_figur = input("Gib die \"Benannte Figur\" ein: ").strip()
        nennende_figur = ""
        if choice == "2":
            nennende_figur = input("Gib die \"Nennende Figur\" ein: ").strip()

        eintrag = {
            "Benannte Figur": benannte_figur,
            "Vers": vers_nr,
            "Eigennennung": benennung if choice == "1" else "",
            "Nennende Figur": nennende_figur,
            "Bezeichnung": benennung if choice == "2" else "",
            "ErzÃ¤hler": benennung if choice == "3" else "",
            "Status": "bestÃ¤tigt"
        }

        # ğŸ“Œ Optionale Kollokation
        will_kollokation = input("ğŸ“Œ MÃ¶chtest du eine Kollokation (Kontextstellen) hinzufÃ¼gen? (j/n): ").strip().lower()
        if will_kollokation == "j":
            print("\nğŸ“– Erweiterter Kontext (1â€“13):")
            vers_kontext = {}
            nummer = 1

            for i in range(6, 0, -1):
                zeile = root.find(f'.//tei:l[@n="{vers_nr - i}"]', tei_ns)
                if zeile is not None:
                    text = ' '.join([seg.text for seg in zeile.findall('.//tei:seg', tei_ns) if seg.text])
                    vers_kontext[nummer] = text
                    print(f"[{nummer}] {text}")
                    nummer += 1

            vers_kontext[nummer] = verse_text
            print(f"[{nummer}] {verse_text}")
            nummer += 1

            for i in range(1, 7):
                zeile = root.find(f'.//tei:l[@n="{vers_nr + i}"]', tei_ns)
                if zeile is not None:
                    text = ' '.join([seg.text for seg in zeile.findall('.//tei:seg', tei_ns) if seg.text])
                    vers_kontext[nummer] = text
                    print(f"[{nummer}] {text}")
                    nummer += 1

            auswahl = input("\nğŸ‘‰ Bitte gib die Versnummer(n) ein (z.B. '5-7' oder '6'): ").strip()
            ausgewaehlt = []

            try:
                if "-" in auswahl:
                    start, ende = map(int, auswahl.split("-"))
                    ausgewaehlt = [vers_kontext[i] for i in range(start, ende + 1) if i in vers_kontext]
                else:
                    idx = int(auswahl)
                    ausgewaehlt = [vers_kontext[idx]]
            except (ValueError, KeyError):
                print("âš ï¸ UngÃ¼ltige Eingabe â€“ keine Kollokation gespeichert.")

            if ausgewaehlt:
                eintrag["Kollokation"] = ' / '.join(ausgewaehlt)

        fehlende_benennungen.append(eintrag)
        speichere_fortschritt(fehlende_benennungen, vers_nr, paths)
        print("âœ… Eintrag gespeichert.")

    return fehlende_benennungen

def lade_fehlende_benennungen(pfad: str) -> list:
    """
    LÃ¤dt fehlende oder bestÃ¤tigte Benennungen aus einer JSON-Datei.
    Gibt eine leere Liste zurÃ¼ck, wenn die Datei nicht existiert oder fehlerhaft ist.
    """
    if os.path.exists(pfad):
        try:
            with open(pfad, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            print("âš ï¸ Fehler beim Laden der JSON-Datei â€“ leere Liste wird verwendet.")
            return []
    else:
        return []

def hole_verskontext(vers_nr, root_tei):
    """Holt die umgebenden 6 Verse aus der TEI-Datei, nummeriert sie von 1â€“13."""
    kontext = []
    vers_liste = []

    for i in range(-6, 7):
        vers_id = str(vers_nr + i)  # explizit String!
        line = root_tei.find(f'.//tei:l[@n="{vers_id}"]', tei_ns)

        if line is not None:
            text = normalisiere_text(' '.join([
                seg.text for seg in line.findall('.//tei:seg', tei_ns) if seg.text
            ]))
            vers_liste.append(text)

    for i, vers in enumerate(vers_liste, start=1):
        kontext.append((i, vers))

    return kontext

def bereinige_zellenwert(value):
    if pd.isna(value) or value is None:
        return ""
    return normalisiere_text(str(value).strip())

def pruefe_und_ergaenze_kollokationen(vers_nr, df, kollokationen_daten, root, paths):

    """PrÃ¼ft, ob eine Kollokation ergÃ¤nzt werden soll â€“ falls ja, ruft UI auf."""

    zeilen = df[df["Vers"] == vers_nr]
    if zeilen.empty:
        return None

    zeile = zeilen.iloc[0]

    if pd.notna(zeile.get("Kollokationen")) and str(zeile["Kollokationen"]).strip() != "":
        return None

    if any(eintrag["Vers"] == vers_nr for eintrag in kollokationen_daten):
        return None

    benennung = bereinige_zellenwert(zeile.get("Eigennennung")) \
                or bereinige_zellenwert(zeile.get("Bezeichnung")) \
                or bereinige_zellenwert(zeile.get("ErzÃ¤hler"))

    benannte_figur = bereinige_zellenwert(zeile.get("Benannte Figur"))

    kontext = hole_verskontext(vers_nr, root)

    kollokationen = frage_nach_kollokationen(vers_nr, benannte_figur, benennung, kontext)

    kollokationen_daten.append({
        "Vers": vers_nr,
        "Kollokationen": kollokationen
    })

    # ğŸ“ Sofortige Zwischenspeicherung nach erfolgreicher Auswahl
    with open(paths["kollokationen_json"], "w", encoding="utf-8") as f:
        json.dump(kollokationen_daten, f, indent=4, ensure_ascii=False)

    return True

def frage_nach_kollokationen(vers_nr, benannte_figur, benennung, kontext):
    """Zeigt den Kontext eines Verses und fragt interaktiv nach relevanten Kollokationen."""

    print(f"\nğŸŸ¡ Leere Kollokationen in Vers {vers_nr} erkannt!")
    if benannte_figur or benennung:
        print(f"ğŸ‘¤ {benannte_figur}: {benennung}\n")

    for nummer, text in kontext:
        if benennung:
            # Benennung hervorheben
            hervorgehoben = text.replace(str(benennung), f"\033[1;33m{benennung}\033[0m")
        else:
            hervorgehoben = text
        print(f"{nummer}. {hervorgehoben}")

    # Nutzereingabe
    eingabe = input("\nğŸ‘‰ Bitte gib die Nummer(n) der relevanten Verse ein (z.â€¯B. '5' oder '5-7'): ")

    # wird unten im return verwendet
    ausgewaehlt = []

    try:
        if "-" in eingabe:
            start, ende = map(int, eingabe.split("-"))
            ausgewaehlt = [text for nummer, text in kontext if start <= nummer <= ende]
        else:
            nummer = int(eingabe)
            ausgewaehlt = [text for num, text in kontext if num == nummer]
    except (ValueError, StopIteration):
        print("âš ï¸ UngÃ¼ltige Eingabe. Bitte eine Zahl oder einen Bereich eingeben.")
        return ""

    return " / ".join(ausgewaehlt)

def lade_kollokationen_json(pfad_zur_datei):
    """LÃ¤dt vorhandene Kollokationen aus einer JSON-Datei â€“ oder gibt leere Liste zurÃ¼ck."""
    if os.path.exists(pfad_zur_datei):
        with open(pfad_zur_datei, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def lade_ignorierte_lemmas(path="ignorierte_lemmas.json"):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            return set(data) if isinstance(data, list) else set(data.keys())
    return set()

def lade_lemma_kategorien(path="lemma_kategorien.json"):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def lade_json_annotationen(path):
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def speichere_json_annotationen(path, annotations):
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(annotations, f, ensure_ascii=False, indent=2)

def lemmatisiere_und_kategorisiere_eintrag(entry, lemma_normalisierung, ignorierte_lemmas=None, lemma_kategorien=None):

    if lemma_normalisierung is None:
        lemma_normalisierung = {}

    if ignorierte_lemmas is None:
        ignorierte_lemmas = lade_ignorierte_lemmas()

    if lemma_kategorien is None:
        lemma_kategorien = lade_lemma_kategorien()

    text = entry.get("ErzÃ¤hler") or entry.get("Bezeichnung") or entry.get("Eigennennung")
    if not text:
        print("âš  Kein Text zum Annotieren vorhanden â€“ Eintrag wird Ã¼bersprungen.\n")
        return None

    print("\n" + "=" * 60)
    print(f"â–¶ Vers: {entry.get('Vers')}")
    print(f"â–¶ Benannte Figur: {entry.get('Benannte Figur')}")
    typ = "ErzÃ¤hler" if entry.get("ErzÃ¤hler") else ("Bezeichnung" if entry.get("Bezeichnung") else "Eigennennung")
    print(f"â–¶ Typ: {typ}")
    print(f"\nâ–¶ Originaltext: {text}")

    if ignorierte_lemmas is None:
        ignorierte_lemmas = lade_ignorierte_lemmas()
    if lemma_kategorien is None:
        lemma_kategorien = lade_lemma_kategorien()

    tokens = zerlege_in_tokens(text.lower())
    fehlende = [t for t in tokens if t not in lemma_normalisierung]

    if fehlende:
        print("\nâ–¶ Lemmata bitte ergÃ¤nzen (getrennt durch Komma):")
        user_input = input("> ").strip()
        neue_lemmata = [l.strip() for l in user_input.split(",") if l.strip()]
        if len(neue_lemmata) != len(fehlende):
            print("âš  Anzahl der eingegebenen Lemmata stimmt nicht mit der Anzahl der unbekannten Tokens Ã¼berein. Vorgang abgebrochen.\n")
            return None
        for token, lemma in zip(fehlende, neue_lemmata):
            lemma_normalisierung[token] = lemma
        speichere_lemma_normalisierung(lemma_normalisierung)

    lemmata = [lemma_normalisierung.get(t, t) for t in tokens]

    print(f"\nâ–¶ Lemma: {', '.join(lemmata)}\n")

    bezeichnungen = []
    epitheta = []
    history = []

    i = 0
    while i < len(lemmata):
        lemma = lemmata[i]
        if lemma in ignorierte_lemmas:
            i += 1
            continue

        vorgabe = f"[{lemma_kategorien.get(lemma, '')}]" if lemma in lemma_kategorien else ""
        print(f"{lemma:<12} â†’ {vorgabe} ", end="")
        user_input = input().strip()

        if user_input == "<":
            if i == 0 or not history:
                print("â†©ï¸  Bereits am Anfang â€“ RÃ¼cksprung nicht mÃ¶glich.")
                continue

            i -= 1
            last_action = history.pop()

            if last_action["type"] == "a":
                bezeichnungen.pop()
            elif last_action["type"] == "e":
                epitheta.pop()
            elif last_action["type"] == "ignore":
                ignorierte_lemmas.discard(last_action["lemma"])
                speichere_ignorierte_lemmas(ignorierte_lemmas)
            elif last_action["type"] == "override":
                del lemma_kategorien[last_action["lemma"]]
                speichere_lemma_kategorien(lemma_kategorien)
            continue

        if user_input == "" and vorgabe:
            if vorgabe == "[a]":
                bezeichnungen.append(lemma)
                history.append({"type": "a", "lemma": lemma})
            elif vorgabe == "[e]":
                epitheta.append(lemma)
                history.append({"type": "e", "lemma": lemma})
            i += 1
            continue

        if user_input == "":
            ignorierte_lemmas.add(lemma)
            speichere_ignorierte_lemmas(ignorierte_lemmas)
            print(f"â„¹ï¸ Lemma â€{lemma}â€œ zur Ignorierliste hinzugefÃ¼gt.")
            history.append({"type": "ignore", "lemma": lemma})
            i += 1
            continue

        if user_input in ("a", "e"):
            if user_input == "a":
                bezeichnungen.append(lemma)
            else:
                epitheta.append(lemma)
            lemma_kategorien[lemma] = user_input
            speichere_lemma_kategorien(lemma_kategorien)
            history.append({"type": user_input, "lemma": lemma})
            i += 1
            continue

        korrektur = user_input
        kat = ""
        while kat not in ("a", "e"):
            kat = input(f'Definiere die Kategorie fÃ¼r â€{korrektur}â€œ [a/e]: ').strip().lower()

        if kat == "a":
            bezeichnungen.append(korrektur)
        else:
            epitheta.append(korrektur)

        lemma_kategorien[korrektur] = kat
        speichere_lemma_kategorien(lemma_kategorien)

        history.append({
            "type": "override",
            "lemma": korrektur
        })
        i += 1

    if not bezeichnungen and not epitheta:
        print("âš  Kein Eintrag â€“ bitte prÃ¼fe und bestÃ¤tige erneut.")
        confirm = input("Eintrag wirklich Ã¼berspringen? [j = ja / n = nein]: ").strip().lower()
        if confirm == "j":
            print("â­ Eintrag wurde Ã¼bersprungen.\n")
            return None
        else:
            return lemmatisiere_und_kategorisiere_eintrag(entry, lemma_normalisierung, ignorierte_lemmas, lemma_kategorien)

    print("âœ… Eintrag automatisch gespeichert.\n")
    return {
        **entry,
        "Bezeichnung 1": bezeichnungen[0] if len(bezeichnungen) > 0 else "",
        "Bezeichnung 2": bezeichnungen[1] if len(bezeichnungen) > 1 else "",
        "Bezeichnung 3": bezeichnungen[2] if len(bezeichnungen) > 2 else "",
        "Bezeichnung 4": bezeichnungen[3] if len(bezeichnungen) > 3 else "",
        "Epitheta 1": epitheta[0] if len(epitheta) > 0 else "",
        "Epitheta 2": epitheta[1] if len(epitheta) > 1 else "",
        "Epitheta 3": epitheta[2] if len(epitheta) > 2 else "",
        "Epitheta 4": epitheta[3] if len(epitheta) > 3 else "",
        "Epitheta 5": epitheta[4] if len(epitheta) > 4 else ""
    }

def zerlege_in_tokens(text):
    return re.findall(r'\w+|[^\w\s]', text, re.UNICODE)

def lade_lemma_normalisierung(path="lemma_normalisierung.json"):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def speichere_lemma_normalisierung(data, path="lemma_normalisierung.json"):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def speichere_ignorierte_lemmas(data, path="ignorierte_lemmas.json"):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(sorted(data), f, ensure_ascii=False, indent=2)

def speichere_lemma_kategorien(data, path="lemma_kategorien.json"):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def main():
    # ğŸ”¹ 1. Initialisierung: Buchwahl, Pfade, letzter Vers
    buchname, letzter_bearbeiteter_vers, paths = initialisiere_projekt()

    # ğŸ”¹ 3. Globales Benennungs-Dict laden (aus allen BÃ¼chern)
    benennungen_dict = lade_oder_erweitere_benennungen_dict()

    # ğŸ”¹ 2. Daten laden: Excel & TEI-XML
    daten = lade_daten()
    df = daten["excel"]
    root = daten["xml"]

    # ğŸ”¹ 4. Vorherigen Vers merken
    vorheriger_vers = letzter_bearbeiteter_vers

    # ğŸ”¹ 5. Initialisierung der Zwischenspeicher
    fehlende_benennungen = []
    kollokationen_daten = []
    vorherige_benennungen = []
    vorherige_kollokationen = []
    kategorisierte_eintraege = []
    vorherige_kategorisierte_eintraege = []

    # ğŸ”¹ 6. Globale Steuerung der Analysepfade (Benennung, Kollokation, Kategorisierung)
    antwort_benennungen = input("Sollen Benennungen geprÃ¼ft und ergÃ¤nzt werden? (j/n): ").strip().lower() == "j"
    antwort_kollokationen = input("Sollen leere Kollokationen befÃ¼llt werden? (j/n): ").strip().lower() == "j"
    antwort_kategorisierung = input("Sollen die Benennungen lemmatisiert und kategorisiert werden? (j/n): ").strip().lower() == "j"

    # ğŸ”¹ 7. Je nach Analysepfad: Daten gezielt laden
    if antwort_benennungen:
        fehlende_benennungen = lade_fehlende_benennungen(paths["benennungen_json"])
        vorherige_benennungen = fehlende_benennungen.copy()

    if antwort_kollokationen:
        kollokationen_daten = lade_kollokationen_json(paths["kollokationen_json"])
        vorherige_kollokationen = kollokationen_daten.copy()


    if antwort_kategorisierung:
        lemma_normalisierung = lade_lemma_normalisierung(paths["lemma_normalisierung_json"])
        ignorierte_lemmas = lade_ignorierte_lemmas(paths["ignorierte_lemmas_json"])
        lemma_kategorien = lade_lemma_kategorien(paths["lemma_kategorien_json"])


    # ğŸ”¹ 8. TEI durchlaufen & gewÃ¤hlte PrÃ¼fungen durchfÃ¼hren
    fehlende_benennungen = durchsuche_tei_mit_dict(
        df=df,
        root=root,
        benennungen_dict=benennungen_dict,
        letzter_vers=letzter_bearbeiteter_vers,
        paths=paths,
        fehlende_benennungen=fehlende_benennungen,
        kollokationen_daten=kollokationen_daten,
        pruefe_benennungen=antwort_benennungen,
        fuehre_kollokationen_durch=antwort_kollokationen,
        fuehre_kategorisierung_durch=antwort_kategorisierung
    )

    # ğŸ”¹ 9. AbschlieÃŸende Sicherung
    speichere_fortschritt(
        fehlende_benennungen=fehlende_benennungen,
        letzter_bearbeiteter_vers=letzter_bearbeiteter_vers,
        paths=paths,
        vorheriger_vers=vorheriger_vers,
        vorherige_benennungen=vorherige_benennungen,
        kollokationen_daten=kollokationen_daten,
        vorherige_kollokationen=vorherige_kollokationen,
        kategorisierte_eintraege=kategorisierte_eintraege,
        vorherige_kategorisierte_eintraege=vorherige_kategorisierte_eintraege
    )




if __name__ == "__main__":
    main()
